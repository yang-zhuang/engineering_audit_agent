# 方法论：从问题到系统的完整设计思路

> 本文档记录了工程资料审核智能体从真实问题到落地系统的完整设计思路，希望能为类似项目提供参考。

## 目录

- [1. 拿到问题/数据源](#1-拿到问题数据源)
- [2. 问题分类体系构建](#2-问题分类体系构建)
- [3. 优先级排序与范围聚焦](#3-优先级排序与范围聚焦)
- [4. 系统架构设计](#4-系统架构设计)
- [5. 实施验证与迭代](#5-实施验证与迭代)
- [6. 关键决策与经验总结](#6-关键决策与经验总结)
  - [6.4 架构选择：为什么使用 LangGraph](#64-架构选择为什么使用-langgraph)
  - [6.5 当前项目的局限性](#65-当前项目的局限性)

---

## 1. 拿到问题/数据源

### 1.1 直接获取真实问题

工程资料审核智能体的目标是：**从一堆工程资料中发现可能存在的问题**。

最直接有效的方式是直接对标真实问题。通过与公司沟通，确认是否有真实存在的问题数据。

#### 本次项目情况

- 直接拿到了两年工程资料的真实问题清单
- 去重后得到 **1091 条问题项**
- 问题以自然语言描述，未进行分类整理

### 1.2 替代方案：问题挖掘

如果没有现成的问题清单，可以考虑以下方式挖掘问题：

1. **AI 辅助问题挖掘**
   - 利用大模型对已有文档进行审计
   - 注入业务知识或行业标准，避免生成不切实际的错误
   - 关注真实场景中常见的问题类型

2. **人工审核记录整理**
   - 收集历史人工审核发现的问题
   - 整理为结构化数据

3. **专家访谈**
   - 与领域专家交流，了解常见问题类型
   - 建立初步的问题库

---

## 2. 问题分类体系构建

拿到原始问题后，需要构建分类体系，以便系统化地解决这些问题。

### 2.1 确定分类策略

面临的两个关键问题：

| 问题 | 决策 | 理由 |
|------|------|------|
| 一次性得到两层分类 vs 先一层再二层 | **先得到第一层，再得到第二层** | 逐步细化，更容易把控，避免一次性生成过多层级导致结构混乱 |
| 全部丢给大模型 vs 逐条归类 | **逐条归类** | 便于质量控制和问题追溯 |

### 2.2 构建一级分类体系

#### 方法：使用 ChatGPT 梳理第一层分类

**Prompt 位置**：`audit_agent/prompts/engineering_doc_level_1_classification.txt`

**模型选择**：ChatGPT（强大的理解和归纳能力）

**执行方式**：多次运行，对比结果，合并分类

**示例对话**：
- https://chatgpt.com/s/t_69a255de99008191ab3352dff851c5df

#### 得到的一级分类

| 分类名称 | 说明 |
|----------|------|
| 规范性问题 | 日期、签名、印章等格式填写规范 |
| 完整性问题 | 文档内容是否完整 |
| 逻辑性问题 | 内容逻辑是否合理 |
| 真实性/可靠性问题 | 数据和内容的真实性 |
| 一致性问题 | 跨文档信息一致性 |
| 合规性/程序性问题 | 是否符合规定流程 |
| 其他 | 难以归类的其他问题 |

### 2.3 对问题进行一级分类

#### 方法：使用小模型批量分类

**Prompt 位置**：`audit_agent/prompts/engineering_document_issue_classification_prompt.txt`

**模型选择**：qwen3-4b（小模型即可胜任分类任务）

**执行方式**：对每条问题独立分类

#### 一级问题分布统计

| 一级分类 | 数量 | 占比 |
|----------|------|------|
| 规范性问题 | 419 | 38.41% |
| 完整性问题 | 357 | 32.72% |
| 逻辑性问题 | 112 | 10.27% |
| 真实性/可靠性问题 | 60 | 5.50% |
| 其他 | 54 | 4.95% |
| 一致性问题 | 50 | 4.58% |
| 合规性/程序性问题 | 39 | 3.57% |

> **分析**：规范性问题和完整性问题是占比最高的两类，合计超过 70%。

---

## 3. 优先级排序与范围聚焦

### 3.1 规则优先级排序原则

在资源有限的情况下，不可能一次性解决所有问题。需要按以下原则排序：

1. **问题占比**：优先解决高频问题
2. **技术可行性**：优先选择可以用 AI 自动化检测的问题
3. **业务价值**：优先选择对业务影响最大的问题
4. **技术成熟度**：优先选择技术方案明确、风险可控的问题

### 3.2 本次项目的优先级决策

与领导沟通后，决定聚焦以下两类问题：

| 优先级 | 问题类型 | 原因 |
|--------|----------|------|
| P0 | 规范性问题 | 占比最高（38.41%），技术方案成熟，业务影响大 |
| P1 | 一致性问题（进销存） | 可用 AI 自动化检测，业务价值明确 |

### 3.3 确定二级分类

对于选定的两类问题，进一步细分，确定具体的检测目标。

#### 规范性问题的二级分类

使用 ChatGPT 对 419 条规范性问题进行二级分类。

**各子类问题分布统计**：

| 子类 | 数量 | 占比 |
|------|------|------|
| 未签字 | 144 | 34.37% |
| 未填写日期 | 136 | 32.46% |
| 未盖章 | 132 | 31.50% |
| 未按手印 | 15 | 3.58% |
| 其他信息未填 | 12 | 2.86% |

**结论**："未签字、未填日期、未盖章" 三类合计占比 **98.33%**，应作为规范性问题自动化检测的首要目标。

#### 一致性问题的二级分类

与领导沟通后，一致性问题主要关注：

1. **数量一致性**：采购合同、送货单、采购入库单之间的物料数量是否一致
2. **时间一致性**：各类单据的日期逻辑是否合理（*注：当前功能已实现但暂时注释*）

---

## 4. 系统架构设计

### 4.1 功能模块划分

根据聚焦的问题类型，将系统分为两个核心模块：

| 模块 | 检测内容 | 技术方案 |
|------|----------|----------|
| 规范性检查 | 日期、印章、签名是否填写 | 视觉模型检测区域 + LLM 提取和验证 |
| 一致性检查 | 跨文档数量、时间一致性 | OCR 识别 + 文档分类 + 数据提取 + 规则验证 |

### 4.2 技术栈选择

| 功能 | 模型 | 理由 |
|------|------|------|
| 视觉区域检测 | qwen3-vl-4B | 需要理解文档版面，4B 参数平衡效果和成本 |
| OCR 识别 | paddleocr-vl 0.9B | 文档 OCR 专用模型，轻量高效 |
| 数据提取与验证 | qwen3-14B | 复杂结构化提取和推理，需要更大参数量 |
| 问题分类（前期） | qwen3-4B | 简单分类任务，小模型足够 |

### 4.3 工作流设计

#### 并行处理架构

规范性检查和一致性检查相互独立，可以并行执行：

```
                    ┌─────────────────┐
                    │   Root Graph    │
                    │  scan_directory │
                    └────────┬────────┘
                             │
                    ┌────────┴────────┐
                    │                 │
            ┌───────▼──────┐  ┌───────▼──────┐
            │   Normative  │  │ Consistency  │
            │    Graph     │  │    Graph     │
            │  (日期/印章/签名) │  │ (数量/时间一致性) │
            └───────┬──────┘  └───────┬──────┘
                    └────────┬────────┘
                             ↓
                      错误汇总输出
```

#### 规范性检查：三步流水线

每个规范性检查项目（日期/印章/签名）采用统一的检测模式：

```
检测区域 (Vision) → 提取标识 (LLM) → 验证内容 (LLM)
    ↓                    ↓                  ↓
  定位字段位置          提取具体值          判断是否合规
```

**优势**：
- 流式处理，文件逐个完成，首个结果快 50%
- 渐进式反馈，用户可以及时查看结果
- 可中断性，随时停止，已完成的结果已保存

#### 一致性检查：文档链式处理

```
1. 文档分类 (LLM)
   ↓ 识别为：采购合同 / 送货单 / 采购入库单

2. 数据提取 (LLM)
   ↓ 提取：日期、物料名称、数量、单位

3. 跨文档验证 (规则引擎)
   ↓ 检查：数量是否一致、日期逻辑是否合理
```

---

## 5. 实施验证与迭代

### 5.1 效果评估

#### 进销存数量一致性评估

**测试数据**：基于 2 个完整工程资料

| 检出情况 | 数量 |
|----------|------|
| 检出"数量不一致"问题 | 20 条 |
| 经人工核验真实问题 | 2 条 |
| 误报数量 | 18 条 |
| **准确率** | **10%** |

**主要误报原因**：

| 原因 | 改进方向 |
|------|----------|
| 单据混杂 | 增加文档拆分识别逻辑 |
| 数值解析失败 | 优化千分位逗号处理 |
| 单位不一致 | 添加单位换算规则 |
| 表格跨页断裂 | 改进 OCR 表格结构识别 |
| OCR 识别偏差 | 优化 OCR 模型或使用混合模式 |
| 印章干扰 | 增加印章区域识别和跳过 |

#### 规范性检查评估

**测试数据**：基于 1 份完整资料

| 检查项 | 检出数量 | 正确数量 | 准确率 |
|--------|----------|----------|--------|
| 未签字 | 6 处 | 6 处 | 100% |
| 未填日期 | 6 处 | 5 处 | 83.3% |
| 未盖章 | 1 处 | 1 处 | 100% |

**改进方向**：当前只处理了"有文字提示"的页面，后续加入无标识页面识别后，预计能大幅提升覆盖范围。

### 5.2 迭代改进方向

1. **问题覆盖扩展**
   - 增加"完整性问题"检查
   - 扩展一致性检查到其他文档类型

2. **准确性提升**
   - 优化 OCR 识别准确率
   - 增加误报过滤规则
   - 引入人工反馈机制

3. **性能优化**
   - 并发处理更多文件
   - 优化模型调用次数
   - 增加结果缓存

---

## 6. 关键决策与经验总结

### 6.1 关键决策回顾

| 决策点 | 选择 | 理由 |
|--------|------|------|
| 数据源选择 | 直接使用真实问题 | 更贴近业务需求 |
| 分类策略 | 先一层再二层 + 逐条归类 | 质量可控，便于追溯 |
| 优先级排序 | 规范性 + 一致性 | 占比高 + 可自动化 |
| 技术架构 | LangGraph + 并行处理 | 工作流清晰，易扩展 |
| 模型选型 | 三种模型各司其职 | 成本效果平衡 |
| 处理模式 | 流式处理 | 首个结果快，用户体验好 |

### 6.2 可复用的方法框架

```
┌─────────────────────────────────────────────────────────┐
│ 步骤 1: 获取问题                                         │
│   - 直接获取真实问题（优先）                             │
│   - 或使用 AI 辅助挖掘                                   │
└─────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────┐
│ 步骤 2: 构建分类体系                                     │
│   - 先构建一级分类                                       │
│   - 再对问题逐条归类                                     │
│   - 统计各类占比                                         │
└─────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────┐
│ 步骤 3: 优先级排序                                       │
│   - 按占比、可行性、价值排序                             │
│   - 与利益相关者确认范围                                 │
└─────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────┐
│ 步骤 4: 二级分类细化                                     │
│   - 对选定的问题类别进一步细分                           │
│   - 确定具体的检测目标                                   │
└─────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────┐
│ 步骤 5: 系统设计与开发                                   │
│   - 设计技术架构                                         │
│   - 选择合适的技术栈                                     │
│   - 逐步实现功能模块                                     │
└─────────────────────────────────────────────────────────┘
                           ↓
┌─────────────────────────────────────────────────────────┐
│ 步骤 6: 效果验证与迭代                                   │
│   - 基于真实数据评估                                     │
│   - 分析误报原因                                         │
│   - 持续优化改进                                         │
└─────────────────────────────────────────────────────────┘
```

### 6.3 经验教训

1. **问题驱动 vs 技术驱动**
   - 从真实问题出发，避免为了用技术而用技术
   - 确保解决的问题有实际业务价值

2. **渐进式方法**
   - 不要一开始就追求完美
   - 先解决高频、高价值问题，再逐步扩展

3. **模型选择原则**
   - 根据任务复杂度选择合适参数量的模型
   - 分类任务用小模型，复杂推理用大模型
   - 视觉、文本、OCR 各司其职

4. **工程化考虑**
   - 流式处理提升用户体验
   - 并行处理提升系统效率
   - 可扩展性设计支持后续扩展

5. **持续的反馈循环**
   - 基于真实数据评估效果
   - 分析误报原因，针对性改进
   - 保持与业务方的沟通，确保方向正确

---

### 6.4 架构选择：为什么使用 LangGraph

在项目初期，团队需要选择一个合适的工作流编排框架。经过评估，最终选择了 LangGraph，主要基于以下考虑：

#### 6.4.1 完整的生态和可视化

**优势**：LangGraph Studio 可以实时展示图/节点的动态变化

**实际价值**：
- 向领导展示时，可以直接展示 workflow 设计图，不需要翻阅代码
- 节点状态实时可视化，便于调试和问题定位
- 支持在 Studio 中直接运行和测试工作流

#### 6.4.2 灵活的编排能力

**子图嵌套支持**：LangGraph 支持创建多个子图，便于团队协作和模块划分

**实际应用示例**：

在 `normative_graph_static.py` 中，规范性检查被拆分为三个独立的子图：

```python
# 并行调用三个独立的规范性检查子图
with StateGraph(NormativeState).add_node("date_checks", date_graph)
with StateGraph(NormativeState).add_node("seal_checks", seal_graph)
with StateGraph(NormativeState).add_node("signature_checks", signature_graph)
```

在 `root_graph.py` 中，两个核心模块并行执行：

```python
# 并行执行规范性和一致性两个子图
with StateGraph(RootState).add_node("normative_graph", normative_subgraph)
with StateGraph(RootState).add_node("consistency_graph", consistency_subgraph)
```

#### 6.4.3 模块化设计支持团队协作

**优势**：不同成员可以单独设计自己的子图和节点，最后由根图统一调用

**协作模式**：
- 成员 A 负责 `date_graph`（日期检查）
- 成员 B 负责 `seal_graph`（印章检查）
- 成员 C 负责 `signature_graph`（签名检查）
- 集成时只需在 `normative_graph_static.py` 中添加对应的节点和边

**代码隔离**：
- 每个子图独立维护，修改一个子图不影响其他子图
- 状态通过命名空间隔离（`date_*`, `seal_*`, `signature_*`），避免冲突
- Reducer 机制自动处理并行状态更新

#### 6.4.4 与其他方案对比

| 特性 | LangGraph | 手写状态机 | Temporal |
|------|-----------|-----------|----------|
| 可视化 | ✅ Studio UI | ❌ 需自绘 | ⚠️ 有限 |
| 子图嵌套 | ✅ 原生支持 | ⚠️ 需自行实现 | ⚠️ 复杂 |
| 并行处理 | ✅ Send API | ⚠️ 需自实现 | ⚠️ Activity |
| 学习曲线 | ⚠️ 中等 | ⚠️ 陡峭 | ✅ 简单 |
| AI 原生 | ✅ | ❌ | ❌ |

**结论**：对于需要可视化、多子图协作的 AI 工作流项目，LangGraph 是更优选择。

---

### 6.5 当前项目的局限性

本节记录第一版架构的不足，作为经验总结和后续迭代改进的方向。

#### 6.5.1 并行设计不充分

**问题描述**：对每张图片的三个步骤（区域检测→标识符检测→内容检测）是串行执行的，未充分利用并行能力。

**证据分析**：

在 `date_graph_streaming.py` 中，使用条件边连接三个节点：

```python
graph.add_conditional_edges(
    "detect_date_in_file",
    should_continue,
    {
        "step2": "extract_date_identifier_in_file",  # step1完成后才能step2
        "end": END
    }
)
graph.add_conditional_edges(
    "extract_date_identifier_in_file",
    should_continue,
    {
        "step3": "verify_date_content_in_file",  # step2完成后才能step3
        "end": END
    }
)
```

在 `normative_state.py` 中，状态字段命名显式体现了串行步骤：

```python
class NormativeState(TypedDict):
    # 每个检查类型有三个串行步骤的字段
    date_step1_results: List[str]    # 区域检测结果
    date_step2_results: List[str]    # 标识符提取结果
    date_step3_results: List[str]    # 内容验证结果

    seal_step1_results: List[str]
    seal_step2_results: List[str]
    seal_step3_results: List[str]

    signature_step1_results: List[str]
    signature_step2_results: List[str]
    signature_step3_results: List[str]
```

**影响**：
- 文件必须完成所有三个步骤才能开始下一文件
- 无法同时处理多个文件的同一阶段
- 资源利用不充分（例如视觉模型空闲时，LLM 也在等待）

**改进方向**：使用 LangGraph 的 Send API 实现更充分的并行处理

```python
# 改进方案：使用 Send API 将每一步独立分发
for file in files:
    # 并行分发所有文件的 step1
    send((file, "step1"), "detect_date_in_file")
    # 同时并行分发已完成 step1 文件的 step2
    send((file, "step2"), "extract_date_identifier_in_file")
```

#### 6.5.2 图/节点维护耦合严重

**问题描述**：添加新审核规则需要修改多处文件，扩展和维护成本高。

**证据分析**：

**状态定义冗余**：每个检查类型有 9 个独立字段

```python
# normative_state.py - 状态定义与业务强耦合
class NormativeState(TypedDict):
    # Date 检查相关的 9 个字段
    date_step1_errors: Annotated[List[ErrorItem], add]
    date_step2_errors: Annotated[List[ErrorItem], add]
    date_step3_errors: Annotated[List[ErrorItem], add]
    date_step1_results: List[str]
    date_step2_results: List[str]
    date_step3_results: List[str]
    date_current_file: str
    date_current_step: int
    date_files_to_process: List[str]

    # Seal 检查相关的 9 个字段（完全类似的结构）
    seal_step1_errors: Annotated[List[ErrorItem], add]
    ...

    # Signature 检查相关的 9 个字段（完全类似的结构）
    signature_step1_errors: Annotated[List[ErrorItem], add]
    ...
```

**节点命名与业务强耦合**：

```
audit_agent/nodes/normative/
├── collect_date_files.py
├── detect_date_in_file.py
├── extract_date_identifier_in_file.py
├── verify_date_content_in_file.py
├── collect_seal_files.py
├── detect_seal_in_file.py
├── extract_seal_identifier_in_file.py
├── verify_seal_content_in_file.py
├── collect_signature_files.py
├── detect_signature_in_file.py
├── extract_signature_identifier_in_file.py
└── verify_signature_content_in_file.py
```

**扩展成本**：新增一个审核规则（如"手印检查"）需要：

1. 创建 3 个节点文件（`collect_handprint_files.py`, `detect_handprint_in_file.py`, `verify_handprint_content_in_file.py`）
2. 创建 1 个子图文件（`handprint_graph_streaming.py`）
3. 修改状态定义（`normative_state.py`）添加 9 个新字段
4. 修改父图（`normative_graph_static.py`）添加新节点和边
5. 修改根图（`root_graph.py`）更新 reducer 配置

**影响**：
- 每次新增审核规则，至少修改 4 个文件，新增 3 个文件
- 状态定义膨胀严重，新增 n 个审核规则需要新增 9n 个字段
- 代码重复度高，三个检查类型的节点逻辑几乎相同

**改进方向**：设计更通用的节点和状态结构

```python
# 改进方案：通用化状态定义
class NormativeState(TypedDict):
    # 通用的三步检查流程，不再与具体业务耦合
    checks: Dict[str, CheckContext]  # key: "date", "seal", "signature"

class CheckContext(TypedDict):
    files: List[str]
    current_file: str
    current_step: int
    step1_results: List[str]
    step2_results: List[str]
    step3_results: List[str]

# 改进方案：通用化节点
def generic_detect_step(state: NormativeState, check_type: str):
    """通用检测节点，通过参数区分检查类型"""
    context = state["checks"][check_type]
    prompt = load_prompt(f"{check_type}_detect.txt")
    # ... 通用处理逻辑
    return state

# 改进方案：动态配置检查规则
CHECK_CONFIG = {
    "date": {
        "detect_prompt": "date_detect.txt",
        "extract_prompt": "date_extract.txt",
        "verify_prompt": "date_verify.txt"
    },
    "seal": { ... },
    "signature": { ... }
}
```

**预期收益**：
- 新增审核规则只需配置 `CHECK_CONFIG`，无需新增节点文件
- 状态定义不再膨胀，支持任意数量的审核规则
- 代码复用率大幅提升

---

## 附录

### A. 关键 Prompt 参考

#### A.1 构建一级分类体系 Prompt

**文件位置**：`audit_agent/prompts/engineering_doc_level_1_classification.txt`

**用途**：基于真实问题描述，分析并构建一级分类体系

**Prompt 内容**：

```text
# 工程资料相关文件夹结构
{一个完整的工程资料文件夹结构}


# 工程资料检查会议纪要
{部分工程资料检查会议纪要问题项}


# 当前任务

上面给出的'工程资料相关文件夹结构'是我其中一个完整工程资料所包含的文件夹目录，而'工程资料检查会议纪要'是根据相应的工程资料整理出来的部分问题（注意该问题可能不是上面列出'工程资料相关文件夹结构'存在的问题，上面'工程资料相关文件夹结构'只是一个示例）。

现在的任务我期望你帮我根据'工程资料检查会议纪要'列出的问题，帮我分析这些问题是否可以分成'完整性问题'、'一致性问题'、'逻辑性问题'等类别，如果可以的话，我期望你帮我分析是否还需要增加其他类别，以及这些类别的问题该怎么定义。

注意：这些问题类别或对应的的标准定义，尽量避免出现重叠和交叉
```

**使用方法**：
1. 将完整的文件夹结构和问题纪要填入对应占位符
2. 使用 ChatGPT 运行多次，对比结果
3. 合并分类，确保类别间不重叠
4. 与业务方确认分类体系

**示例对话**：
- https://chatgpt.com/s/t_69a255de99008191ab3352dff851c5df

---

#### A.2 问题分类 Prompt

**文件位置**：`audit_agent/prompts/engineering_document_issue_classification_prompt.txt`

**用途**：对每条问题描述进行一级分类

**Prompt 内容**（节选）：

```text
你是一名工程资料审计与内控专家，熟悉工程管理、合同管理、成本管理及资料归档规范。

下面给出一条【工程资料检查会议纪要中的问题描述】，请你依据以下【工程资料问题分类体系】，对该问题进行【唯一且排他的分类判断】。

——————————————————
【工程资料问题分类体系（审计级定义）】
——————————————————

【A 类｜完整性问题】
- 定义：在工程管理、合同管理、财务或档案制度中，明确要求必须存在的资料或单据，在被检查资料范围内【完全不存在任何实体或电子形式】的记录...
- 判定标准：被检查范围内完全找不到该资料...
- 典型特征：缺、无、未提供、未提交、未见、未附...

【B 类｜规范性问题】
- 定义：资料或单据【可以被看到、找到或调取到】，但其填写要素、格式或形式不符合制度、合同或管理要求...
- 典型特征：未填写日期、未签字、未盖章、编号缺失、格式错误...

【C 类｜一致性问题】
- 定义：同一工程事项，在两份或以上有效资料之间，存在数量、金额、内容、对象、累计结果不一致的情况...
- 典型场景：送货单与入库单不一致；出库数量与劳务结算工程量不一致...

【D 类｜逻辑性问题】
- 定义：资料虽存在且形式合规，但不符合正常工程实施顺序、业务流程或时间逻辑...
- 典型场景：未中标先采购；未开工先结算；一天内出库即完成安装...

【E 类｜合规性 / 程序性问题】
- 定义：工程管理行为违反合同约定、制度条款或审批流程...
- 典型场景：超期签订合同；合同约定违约金但未执行；工程延期未履行审批...

【F 类｜真实性 / 可靠性问题】
- 定义：资料存在，但存在明显迹象表明其真实性或可信度不足...
- 典型场景：明显涂改；日期反复修改；签收早于送货...

【G 类｜非资料问题 / 不适用问题】
- 定义：问题描述不涉及工程资料的完整性、规范性、一致性、逻辑性、合规性或真实性...
- 使用限制：仅当 A–F 类均不适用时，方可选择 G 类...

——————————————————
【分类规则（必须遵守）】
——————————————————
1. 只能选择一个问题类别；
2. 禁止多选、禁止模糊判断；
3. 若同时符合多个特征，选择风险等级最高的类别（F > D > E > C > B > A > G）；
4. 不得自行新增、合并或拆分类别。

——————————————————
【输出要求】
——————————————————

输出内容必须严格符合以下 JSON 结构：

{
  "category_code": "",
  "category_name": "",
  "judgement_reason": ""
}

category_code 只能是 "A" "B" "C" "D" "E" "F" "G" 之一；
category_name 必须与 category_code 一一对应；
judgement_reason 用一句话说明核心判定依据，不超过 30 个汉字。

——————————————————
【问题描述】
——————————————————
{{在此粘贴一条工程资料检查会议纪要中的问题}}
```

**使用方法**：
1. 将单条问题描述填入占位符
2. 使用小模型（如 qwen3-4b）批量处理
3. 输出为结构化 JSON，便于后续统计
4. 统计各类别占比，分析问题分布

**模型选择**：
- ChatGPT：前期探索和验证
- 小模型（qwen3-4b）：批量处理，成本低

---

### B. 分类体系定义参考

最终确定的工程资料问题分类体系：

| 代码 | 类别 | 定义 |
|------|------|------|
| A | 完整性问题 | 资料完全缺失，无法找到任何形式的记录 |
| B | 规范性问题 | 资料存在但填写要素、格式不符合要求 |
| C | 一致性问题 | 跨资料之间数量、金额、内容不一致 |
| D | 逻辑性问题 | 资料存在但不符合正常实施顺序或时间逻辑 |
| E | 合规性/程序性问题 | 违反合同约定、制度条款或审批流程 |
| F | 真实性/可靠性问题 | 资料存在但真实性或可信度存疑 |
| G | 非资料问题 | 不涉及资料审查的问题 |

**优先级**：F > D > E > C > B > A > G

### C. 相关文档链接

- [系统架构说明](architecture.md) - 详细的技术架构和数据流
- [配置指南](configuration.md) - 完整的配置选项说明
- [开发指南](development.md) - 开发环境搭建和代码规范

---

**文档版本**：1.0
**最后更新**：2026-02-28