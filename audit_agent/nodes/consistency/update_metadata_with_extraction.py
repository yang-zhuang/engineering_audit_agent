"""
Node: update_metadata_with_extraction

ä¿å­˜metadata.jsonï¼ˆåŒ…å«åˆ†ç±»ç»“æœå’Œæå–ç»“æœï¼‰

Responsibility:
- å¦‚æœmetadata.jsonå·²å­˜åœ¨ï¼šè¯»å–å¹¶æ›´æ–°æå–ç»“æœ
- å¦‚æœmetadata.jsonä¸å­˜åœ¨ï¼šä»ocr_current_group_metadataåˆ›å»ºæ–°æ–‡ä»¶
- å°†æå–ç»“æœåˆå¹¶åˆ°metadataä¸­
- ä¿å­˜æœ€ç»ˆçš„metadata.json

Note:
    æ­¤èŠ‚ç‚¹æ˜¯æ–‡ä»¶I/Oæ“ä½œçš„å”¯ä¸€å…¥å£ç‚¹
    åœ¨æµç¨‹æœ€åç»Ÿä¸€ä¿å­˜æ‰€æœ‰ç»“æœï¼ˆåˆ†ç±»+æå–+æ£€æŸ¥ï¼‰
    ç¡®ä¿æ¯ä¸ªIOCç»„åªè¿›è¡Œä¸€æ¬¡æ–‡ä»¶å†™å…¥æ“ä½œ
"""
import os
import json
from datetime import datetime
from audit_agent.config.extraction_config import (
    EXTRACTION_STATUS_FIELD,
    EXTRACTION_RESULTS_FIELD,
    EXTRACTION_TIMESTAMP_FIELD,
    ExtractionStatus
)


def update_metadata_with_extraction(state):
    """
    ä¿å­˜metadata.jsonï¼ˆåŒ…å«åˆ†ç±»ã€æå–ã€æ£€æŸ¥ç»“æœï¼‰

    Processing logic:
    - Get OCR results base path and metadata file path
    - If metadata.json exists: read and update with extraction results
    - If metadata.json doesn't exist: create from ocr_current_group_metadata
    - Merge extraction results into metadata
    - Update extraction status
    - Save final metadata.json

    State updates:
    - ocr_metadata: Updated with extraction results
    - extraction_current_ioc_group_key: Clear
    - ocr_current_ioc_group_key: Clear
    - ocr_current_ioc_group_index: Increment (move to next group)

    Note:
        This is the FINAL file I/O node for each IOC group
        Saves all results in one operation (classification + extraction + checking)
    """
    import copy

    ioc_group_key = state.get("extraction_current_ioc_group_key")
    group_idx = state.get("ocr_current_ioc_group_index", 0)
    # æ³¨æ„ï¼šextraction_results ç»“æ„å·²ç®€åŒ–ï¼Œä¸å†æœ‰ ioc_group_key å±‚çº§
    extraction_results = state.get("extraction_results", {})

    if not ioc_group_key:
        # No results to update
        return {
            "extraction_current_ioc_group_key": None,
            "extraction_current_ioc_group_index": group_idx + 1,
            "ocr_current_ioc_group_key": None,  # æ·»åŠ è¿™ä¸ªå­—æ®µ
            "ocr_current_ioc_group_index": group_idx + 1  # ä¿®å¤ï¼šæ·»åŠ è¿™ä¸ªå­—æ®µ
        }

    # Get OCR results base path
    from dotenv import load_dotenv
    load_dotenv()

    base_path = os.getenv("OCR_RESULTS_BASE_PATH")
    if not base_path:
        error_msg = "ç¯å¢ƒå˜é‡ OCR_RESULTS_BASE_PATH æœªè®¾ç½®"
        print(f"  âœ— {error_msg}")
        return {
            "extraction_current_ioc_group_key": None,
            "extraction_current_ioc_group_index": group_idx + 1,
            "ocr_current_ioc_group_key": None,  # æ·»åŠ 
            "ocr_current_ioc_group_index": group_idx + 1  # ä¿®å¤ï¼šæ·»åŠ 
        }

    project_ioc_roots = state.get("project_ioc_roots", {})
    project_name = project_ioc_roots.get("project_name", "æœªçŸ¥é¡¹ç›®")
    ioc_folder_name = project_ioc_roots.get("ioc_folder_name", "æœªçŸ¥iocæ–‡ä»¶å¤¹")

    metadata_file_path = os.path.join(
        base_path, project_name, ioc_folder_name, ioc_group_key, "metadata.json"
    )

    # æ³¨æ„ï¼šç§»é™¤äº†æå‰è¿”å›é€»è¾‘ï¼Œå› ä¸ºå³ä½¿metadata.jsonä¸å­˜åœ¨ä¹Ÿåº”è¯¥åˆ›å»ºå®ƒ
    # åœ¨ä¸‹é¢çš„tryå—ä¸­ä¼šå¤„ç†æ–‡ä»¶ä¸å­˜åœ¨çš„æƒ…å†µ

    try:
        print(f"\n=== ä¿å­˜metadata.json: {ioc_group_key} ===")
        print(f"  ğŸ“‚ è·¯å¾„: {metadata_file_path}")

        # Check if metadata file exists
        if os.path.exists(metadata_file_path):
            # Read existing metadata and update it
            with open(metadata_file_path, 'r', encoding='utf-8') as f:
                metadata_list = json.load(f)
            print(f"  âœ“ è¯»å–ç°æœ‰ metadata.json ({len(metadata_list)} ä¸ªæ–‡ä»¶)")
        else:
            # Create new metadata from ocr_current_group_metadata
            metadata_list = state.get("ocr_current_group_metadata", [])
            print(f"  âœ“ åˆ›å»ºæ–°çš„ metadata.json ({len(metadata_list)} ä¸ªæ–‡ä»¶)")

            if not metadata_list:
                print(f"  âš  è­¦å‘Š: ocr_current_group_metadata ä¸ºç©ºï¼Œå°†åˆ›å»ºç©ºçš„ metadata.json")

        # Update each metadata item with extraction results
        updated_count = 0
        for metadata in metadata_list:
            original_file = metadata.get("åŸå§‹æ–‡ä»¶è·¯å¾„")

            if original_file in extraction_results:
                # Merge extraction results
                file_extraction_results = extraction_results[original_file]

                # Update or create extraction results field
                if EXTRACTION_RESULTS_FIELD not in metadata:
                    metadata[EXTRACTION_RESULTS_FIELD] = {}

                metadata[EXTRACTION_RESULTS_FIELD].update(file_extraction_results)

                # Update extraction status
                metadata[EXTRACTION_STATUS_FIELD] = ExtractionStatus.COMPLETED
                metadata[EXTRACTION_TIMESTAMP_FIELD] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                updated_count += 1

        # Ensure directory exists before saving
        metadata_dir = os.path.dirname(metadata_file_path)
        if metadata_dir and not os.path.exists(metadata_dir):
            os.makedirs(metadata_dir, exist_ok=True)
            print(f"  âœ“ åˆ›å»ºç›®å½•: {metadata_dir}")

        # Save updated metadata
        with open(metadata_file_path, 'w', encoding='utf-8') as f:
            json.dump(metadata_list, f, ensure_ascii=False, indent=2)

        print(f"  âœ“ å·²ä¿å­˜ {updated_count} ä¸ªæ–‡ä»¶çš„æå–ç»“æœ")
        print(f"  âœ“ å·²ä¿å­˜: {metadata_file_path}")
        print(f"=== metadataä¿å­˜å®Œæˆ ===\n")

        # Update ocr_metadata in state
        ocr_metadata = copy.deepcopy(state.get("ocr_metadata", {}))
        ocr_metadata[ioc_group_key] = metadata_list

        # Prepare for next IOC group by clearing current group state
        return {
            "ocr_metadata": ocr_metadata,
            "ocr_current_group_metadata": [],  # Clear for next group
            "ocr_current_ioc_group_key": None,  # Clear current group key
            "ocr_current_ioc_group_index": group_idx + 1,  # Move to next group
            "extraction_current_ioc_group_key": None,  # Clear extraction tracking
            "extraction_current_ioc_group_index": group_idx + 1,  # Sync with OCR index
            "extraction_results": {}  # Clear extraction results for next group
        }

    except Exception as e:
        error_msg = f"æ›´æ–°metadataå¤±è´¥: {e}"
        print(f"  âœ— {error_msg}")
        import traceback
        traceback.print_exc()

        # Add error to state
        errors = list(state.get("errors", []))
        from audit_agent.schemas.error_item import ErrorItem
        errors.append(ErrorItem(
            error_type="metadataæ›´æ–°é”™è¯¯",
            error_location=f"IOCç»„: {ioc_group_key}",
            error_description=error_msg,
            related_file=metadata_file_path
        ))

        return {
            "errors": errors,
            "ocr_current_group_metadata": [],  # Clear for next group
            "ocr_current_ioc_group_key": None,  # Clear current group key
            "ocr_current_ioc_group_index": group_idx + 1,  # Move to next group
            "extraction_current_ioc_group_key": None,
            "extraction_current_ioc_group_index": group_idx + 1,
            "extraction_results": {}  # Clear extraction results for next group
        }
