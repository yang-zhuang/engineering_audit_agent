# ============================================================================
# Engineering Document Audit Agent - Environment Configuration
# ============================================================================
# This file contains all configuration options for the audit agent.
# Copy this file to .env and fill in your actual values.
#
# Configuration Priority:
# 1. Environment variables (.env file) - Highest priority
# 2. Default values in code - Lowest priority
# ============================================================================

# ============================================================================
# LangSmith Tracing (Optional)
# ============================================================================
# Enable tracing for debugging and monitoring
# Get API key: https://smith.langchain.com/
LANGCHAIN_TRACING_V2=true
LANGSMITH_API_KEY=your-langsmith-api-key-here
LANGSMITH_PROJECT=engineering-audit-agent

# ============================================================================
# Vision Model Configuration (Required)
# ============================================================================
# Vision model for detecting date fields, seals, and signatures
# Note: This model is for visual recognition, not OCR (text extraction)
#
# Current: Qwen3-VL-4B-Instruct via local OpenAI-compatible API

# Vision model API endpoint (local deployment)
VISION_MODEL_BASE_URL=http://localhost:8000/v1
VISION_MODEL_API_KEY=your-vision-model-api-key-here  # Virtual key for local deployment
VISION_MODEL_NAME=Qwen3-VL-4B-Instruct

# ============================================================================
# OCR Engine Configuration (Required)
# ============================================================================
# OCR engine for extracting text from documents and images
#
# Three working modes:
# Mode 1 - Local only: Fully use local PaddleOCR-VL service
# Mode 2 - Official API only: Fully use PaddlePaddle AI Studio free API (daily quota limit)
# Mode 3 - Hybrid mode (recommended): Prioritize official API, auto-fallback to local
#
# Note: Default is hybrid mode for balanced speed and reliability

# ===== OCR Work Mode Selection =====
# Options: local_only, api_only, hybrid (default, recommended)
OCR_WORK_MODE=hybrid

# ===== Mode 1: Local Deployment Configuration =====
# PaddleOCR-VL backend type (fixed to vllm-server)
PADDLE_VL_REC_BACKEND=vllm-server
# PaddleOCR-VL server address
PADDLE_VL_SERVER_URL=http://localhost:8000/v1

# ===== Mode 2: Official API Configuration =====
# PaddlePaddle AI Studio API endpoint (free, daily quota limit)
# Register at: https://aistudio.baidu.com/
PADDLE_API_URL=https://your-api-url.aistudio-app.com/layout-parsing
PADDLE_API_TOKEN=your-paddle-api-token-here

# ============================================================================
# Language Model Configuration (Required)
# ============================================================================
# Language model for structured data extraction and consistency checks
# Current: Qwen3-14B-Instruct local deployment

# Language model API endpoint (local deployment)
LLM_BASE_URL=http://127.0.0.1:6006/v1
LLM_API_KEY=your-llm-api-key-here  # Virtual key for local deployment
LLM_MODEL_NAME=Qwen3-14B-AWQ
LLM_TEMPERATURE=0.1  # Temperature (lower = more stable)
LLM_MAX_TOKENS=15000  # Max output tokens

# Alternative: Use cloud API
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_API_KEY=your_openai_api_key_here
# LLM_MODEL_NAME=gpt-4-turbo-preview

# ============================================================================
# OCR Result Storage (Required)
# ============================================================================
# Base path for storing OCR results and metadata
# Directory structure: BASE_PATH/Project_Name/IOC_Group_Name/metadata.json

OCR_RESULTS_BASE_PATH=D:/Code/Your_Project/OCR_Results

# ============================================================================
# Image Processing Configuration
# ============================================================================
# Poppler path for PDF-to-image conversion (Windows only)
# Download: https://github.com/oschwartz10612/poppler-windows/releases/
POPLER_PATH=D:/poppler-25.12.0/Library/bin

# PDF-to-image DPI (higher = better quality, but slower)
PDF_TO_IMAGE_DPI=200

# ============================================================================
# Processing Options
# ============================================================================
# Graph architecture selection (Static vs Dynamic)
# Options:
#   0 - Dynamic version (Map-Reduce, default, recommended for production)
#       - Uses Send API for parallel processing
#       - Fixed recursion depth (~20-30 steps)
#       - Supports unlimited data growth
#       - Best for: Large datasets (>= 50 files), production use
#   1 - Static version (Loop-based, recommended for development)
#       - Uses conditional edge loops
#       - Recursion depth scales with data O(n)
#       - Full Studio visualization support
#       - Best for: Development, debugging, small datasets (< 100 files)
USE_STATIC_GRAPH=1

# Maximum concurrent file processing (performance tuning)
MAX_CONCURRENT_FILES=5

# Enable verbose logging
VERBOSE_LOGGING=true

# Enable checkpointing (support resumable workflows)
ENABLE_CHECKPOINTING=true
CHECKPOINT_DB_PATH=./checkpoints.db

# ============================================================================
# Performance Tuning
# ============================================================================
# Vision model batch size (process multiple pages at once)
VISION_MODEL_BATCH_SIZE=4

# OCR processing timeout (seconds)
OCR_TIMEOUT=300

# Maximum API retry attempts
MAX_RETRIES=3

# ============================================================================
# Advanced Options (Optional)
# ============================================================================
# Custom prompts directory (to override default prompts)
# CUSTOM_PROMPTS_DIR=./custom_prompts

# Disable model source check (speed up startup)
# DISABLE_MODEL_SOURCE_CHECK=true

# Background job isolation (production deployment)
# BG_JOB_ISOLATED_LOOPS=true

# LangGraph recursion limit (support processing more files)
# Each file needs 3 recursions (detect + extract + verify)
# Set to 300 to support ~100 files, 1000 to support ~333 files
LANGGRAPH_RECURSION_LIMIT=1000
